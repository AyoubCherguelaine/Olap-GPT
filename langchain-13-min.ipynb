{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabbitmetrics/langchain-13-min/blob/main/notebooks/langchain-13-min.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "50dvxjqCFmhF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load environment variables\n",
        "\n",
        "from dotenv import load_dotenv,find_dotenv\n",
        "load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "C7RnyUOCJWmk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n\\nLarge language models are artificial neural networks that are trained on large text corpora to predict the next word or character in a sequence.'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run basic query with OpenAI wrapper\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(model_name=\"text-davinci-003\")\n",
        "llm(\"explain large language models in one sentence\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JtHgQ5XpJmgi"
      },
      "outputs": [],
      "source": [
        "# import schema for chat messages and ChatOpenAI in order to query chatmodels GPT-3.5-turbo or GPT-4\n",
        "\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yrfYfKfdJyyF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Certainly! Here's an example script that trains a simple neural network on simulated data using the Keras library:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "from keras.models import Sequential\n",
            "from keras.layers import Dense\n",
            "\n",
            "# Generate simulated data\n",
            "np.random.seed(0)\n",
            "X = np.random.rand(100, 2)\n",
            "y = np.random.randint(0, 2, size=(100,))\n",
            "\n",
            "# Define the model architecture\n",
            "model = Sequential()\n",
            "model.add(Dense(10, input_dim=2, activation='relu'))\n",
            "model.add(Dense(1, activation='sigmoid'))\n",
            "\n",
            "# Compile the model\n",
            "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
            "\n",
            "# Train the model\n",
            "model.fit(X, y, epochs=10, batch_size=10)\n",
            "\n",
            "# Evaluate the model\n",
            "loss, accuracy = model.evaluate(X, y)\n",
            "print(f\"Loss: {loss}\")\n",
            "print(f\"Accuracy: {accuracy}\")\n",
            "```\n",
            "\n",
            "In this script, we first generate a simulated dataset with 100 samples and 2 features. We then define a simple neural network model with one hidden layer of 10 neurons and an output layer with one neuron. The model is compiled with binary cross-entropy loss and the Adam optimizer.\n",
            "\n",
            "Next, we train the model on the simulated data for 10 epochs with a batch size of 10. Finally, we evaluate the trained model on the same data and print the loss and accuracy.\n",
            "\n",
            "You can modify this script to suit your specific requirements, such as changing the model architecture, loss function, optimizer, or adding more layers.\n"
          ]
        }
      ],
      "source": [
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.3)\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are an expert data scientist\"),\n",
        "    HumanMessage(content=\"Write a Python script that trains a neural network on simulated data \")\n",
        "]\n",
        "response=chat(messages)\n",
        "\n",
        "print(response.content,end='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2grf7I8AJ_hK"
      },
      "outputs": [],
      "source": [
        "# Import prompt and define PromptTemplate\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "You are an expert data scientist with an expertise in building deep learning models. \n",
        "Explain the concept of {concept} in a couple of lines\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"concept\"],\n",
        "    template=template,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vcz7Q9Y-KFvI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nAn autoencoder is a type of neural network that is used to learn efficient data codings in an unsupervised manner. It consists of an encoder which compresses the input into a lower dimensional representation and a decoder which reconstructs the input from this lower dimensional representation.'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run LLM with PromptTemplate\n",
        "\n",
        "llm(prompt.format(concept=\"autoencoder\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dm78i-rUKXIB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Autoencoders are a type of neural network used for learning efficient representations of data. They are trained to reconstruct their input, which forces the network to learn a compressed representation of the input data that captures its most important characteristics. Autoencoders can be used for a variety of tasks, such as dimensionality reduction, denoising, and feature extraction.\n"
          ]
        }
      ],
      "source": [
        "# Import LLMChain and define chain with language model and prompt as arguments.\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "print(chain.run(\"autoencoder\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "B6MF4-nMKul3"
      },
      "outputs": [],
      "source": [
        "# Define a second prompt \n",
        "\n",
        "second_prompt = PromptTemplate(\n",
        "    input_variables=[\"ml_concept\"],\n",
        "    template=\"Turn the concept description of {ml_concept} and explain it to me like I'm five in 500 words\",\n",
        ")\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SkJKFyk1K-MO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "An autoencoder is a type of artificial neural network used to learn efficient data encodings in an unsupervised manner. It is comprised of an encoder and a decoder, which learn to compress and decompress data, respectively. Autoencoders are used for feature learning, dimensionality reduction, and reconstruction of inputs.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "\n",
            "An Autoencoder is a special type of neural network that helps computers learn how to better understand data. It’s made up of two different parts: an encoder and a decoder. \n",
            "\n",
            "The encoder’s job is to take data (like an image or a sound) and make it smaller and simpler. It does this by breaking the data down into smaller pieces. The encoder takes the data and stores it in a format that takes up less space. \n",
            "\n",
            "The decoder’s job is to take the simplified data from the encoder and turn it back into something useable. The decoder takes the smaller pieces of data and builds it back up into something that’s easy to use. \n",
            "\n",
            "An Autoencoder is used to help computers learn how to better understand data without needing to be taught. It does this by taking the data, breaking it down, and then rebuilding it in a way that’s easier to understand. This process is done in an unsupervised manner, meaning the Autoencoder figures out how to do it without any help. \n",
            "\n",
            "Autoencoders are also used for feature learning, dimensionality reduction, and reconstruction of inputs\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "An Autoencoder is a special type of neural network that helps computers learn how to better understand data. It’s made up of two different parts: an encoder and a decoder. \n",
            "\n",
            "The encoder’s job is to take data (like an image or a sound) and make it smaller and simpler. It does this by breaking the data down into smaller pieces. The encoder takes the data and stores it in a format that takes up less space. \n",
            "\n",
            "The decoder’s job is to take the simplified data from the encoder and turn it back into something useable. The decoder takes the smaller pieces of data and builds it back up into something that’s easy to use. \n",
            "\n",
            "An Autoencoder is used to help computers learn how to better understand data without needing to be taught. It does this by taking the data, breaking it down, and then rebuilding it in a way that’s easier to understand. This process is done in an unsupervised manner, meaning the Autoencoder figures out how to do it without any help. \n",
            "\n",
            "Autoencoders are also used for feature learning, dimensionality reduction, and reconstruction of inputs\n"
          ]
        }
      ],
      "source": [
        "# Define a sequential chain using the two chains above: the second chain takes the output of the first chain as input\n",
        "\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
        "\n",
        "# Run the chain specifying only the input variable for the first chain.\n",
        "explanation = overall_chain.run(\"autoencoder\")\n",
        "print(explanation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mDDu1B_SLQls"
      },
      "outputs": [],
      "source": [
        "# Import utility for splitting up texts and split up the explanation given above into document chunks\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 100,\n",
        "    chunk_overlap  = 0,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([explanation])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "F6lfAdeuLhtp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='An Autoencoder is a special type of neural network that helps computers learn how to better', metadata={}),\n",
              " Document(page_content='understand data. It’s made up of two different parts: an encoder and a decoder.', metadata={}),\n",
              " Document(page_content='The encoder’s job is to take data (like an image or a sound) and make it smaller and simpler. It', metadata={}),\n",
              " Document(page_content='does this by breaking the data down into smaller pieces. The encoder takes the data and stores it in', metadata={}),\n",
              " Document(page_content='a format that takes up less space.', metadata={}),\n",
              " Document(page_content='The decoder’s job is to take the simplified data from the encoder and turn it back into something', metadata={}),\n",
              " Document(page_content='useable. The decoder takes the smaller pieces of data and builds it back up into something that’s', metadata={}),\n",
              " Document(page_content='easy to use.', metadata={}),\n",
              " Document(page_content='An Autoencoder is used to help computers learn how to better understand data without needing to be', metadata={}),\n",
              " Document(page_content='taught. It does this by taking the data, breaking it down, and then rebuilding it in a way that’s', metadata={}),\n",
              " Document(page_content='easier to understand. This process is done in an unsupervised manner, meaning the Autoencoder', metadata={}),\n",
              " Document(page_content='figures out how to do it without any help.', metadata={}),\n",
              " Document(page_content='Autoencoders are also used for feature learning, dimensionality reduction, and reconstruction of', metadata={}),\n",
              " Document(page_content='inputs', metadata={})]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Individual text chunks can be accessed with \"page_content\"\n",
        "\n",
        "texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Z5sv4e3tLw2y"
      },
      "outputs": [],
      "source": [
        "# Import and instantiate OpenAI embeddings\n",
        "\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model_name=\"ada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dqzoir4hMlfl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.030426677826509596, 0.034438308905724725, 0.008450140386919611, 0.01471959917336777, 0.035631511957744715, 0.011746878001326882, -0.023905205009790795, 0.0012266333420575298, 0.030262098223654783, -0.00018547363599168737, -0.038223643496675785, -0.02050046284591732, 0.013310385159770195, 0.01953355628216141, 0.011078273131898558, -0.011726306016631325, 0.03624868453712767, 0.006254029565095844, 0.017414592498421807, 0.010023934003371997, 0.033121672082886223, -0.006938064121537779, 0.07262080284507386, -0.011067986673889484, 0.012662353206360017, 0.02590073502271188, 0.015645360836409977, 0.05916641379243477, -0.010502243590584121, -0.023411466201226357, -0.02606531462556669, 0.017167723094139588, 0.03777104679485728, 0.024419516734373384, 0.043572482452102386, 0.022938300308680066, 0.0255921487330204, -0.011500008597044663, -0.027032221189322605, -0.016385969049256637, 0.015851084408655902, -0.01736316113969903, 0.0005056326711565846, 0.008280418020721556, -0.016643125842870518, -0.008270131562712483, -0.05978358637181773, 0.015305915172691278, -0.02898660537020739, 0.04468339756534015, 0.014925324608258876, 0.029110039141025914, 0.0057037161688040915, 0.03266907538106772, -0.0057911491992360346, -0.050731700764222294, 0.034458879959097695, -0.03725673693291988, -0.0322987703433218, -0.02435779984896412, 0.011582298398472069, -0.02898660537020739, -0.003116728557369496, 0.023473183086635617, -0.08467626713609222, -0.04349019451332016, 0.009648486202282836, -0.004199354514098417, 0.005017110230690535, -0.049209338506492686, -0.007560381326909159, 0.04900361307160158, 0.015861371797987567, -0.06134709446158363, -0.002705279317401816, -0.025674438534447806, 0.01217889992448206, -0.006392893954250563, 0.030323815109064043, -0.004284216162858739, 0.004070776582952771, 0.006639763358532782, 0.0030138663055852377, -0.019636418999606962, -0.018186061016618276, 0.03503491043173472, -0.005657428039085852, -0.04128893906550797, -0.0009039027069422797, -0.030447250742527743, 0.05262436805969782, 0.012754929465796497, -0.03830593143545801, 0.01251834558820076, 0.027443670196459637, -0.0054722759858741865, 0.04353133662006609, 0.02000672403735288, -0.03168159776393884, 0.01416414254807148, -0.0066089049158281525, -0.03211361968709402, -0.04163867304988093, -0.04628804776185198, 0.007328941143979255, 0.0424204252321187, -0.03717444526884729, -0.01556307103498257, -0.013567541022061489, -0.000836399339656945, -0.003885624529741106, -0.013865841785066484, 0.011860027176781508, -0.02931576457591702, 0.0408157713103165, 0.055545658804338524, 0.0074523758461203645, 0.059742440539781436, -0.0037621898275999963, 0.050361395726476375, -0.008784443287295069, 0.01596423451543312, -0.006814629419396669, 0.01124285273475337, 0.03587837949938175, 0.016704842728279778, 0.008264987868046652, -0.028739735965925172, 0.005883725458672514, 0.01751745521586736, 0.07665301242824268, 0.01071825455216171, -0.019626133472920478, -0.009422189714018763, -0.015233910897950355, 0.004919390742249519, -0.0064340388549642665, 0.045917742724106064, 0.07027554629836055, -0.02851343761501592, -0.006881489999471761, 0.0042327848041359625, 0.022321125866651928, -0.0014182144315248654, -0.0043279324452440635, 0.05879610875468885, -0.013536682579356859, 0.03215476551913031, 0.02631218402984891, -0.0317433146493481, 3.174267165841104e-05, -0.02062389661673584, -0.008357564127483131, 0.04768697624876307, 0.06200541287300288, 0.019338118236601965, -0.046329193593888277, 0.04698751200530753, -0.006819772648401206, -0.012096610123054654, 0.0032298772671628274, 0.03375941571564215, -0.055833672178011856, 0.01870037087855568, -0.03180503153475736, -0.049332772277311206, -0.03303938041881364, -0.012868077709928533, 0.0021459653867674485, -0.0013333530155951905, 0.016190531003697193, 0.04842758632425491, -0.027073365158713718, -0.0040656338196095295, 0.042379279400082404, -0.0201301578081714, 0.01648883176670219, -0.029274618743880727, -0.03581666261397249, 0.019368976679306597, 0.05628626887983036, 0.038100206000566905, 0.025365850382111147, 0.03447945473776102, 0.013968704502512037, -0.011942316978208915, 0.0655850257543532, -0.01717800862082607, 0.006932920892533242, 0.02105591853989102, 0.012868077709928533, -0.04155638138580834, 0.05719145483288665, 0.021251358448095642, -0.006891775991819539, 0.009278182095859507, 0.001639368389276344, -0.035734374675190264, -0.04455996006923127, -0.000676962732976021, 0.032525070556876236, 0.015172194012541095, 0.005888868222015756, 0.048633311759146015, 0.014832748348822396, 0.01574822355385553, 0.03655727268946433, -0.005914583901377144, -0.004050204132595919, -0.010419953789156715, -0.004183925292746102, -0.03392399531849696, 0.01822720498600939, -0.016200816530383674, 0.0127960743665102, 0.009586769316873576, 0.01699285796459829, -0.041618098271217596, 0.03865566541983097, 0.03349197339534178, -0.03207247385505772, -0.016632838453538856, 0.0016265105495956499, 0.00885130386737016, -0.006485469748025748, -0.005868295771658904, -0.03668070646028285, -0.012189186382491135, -0.03221648240453957, 0.028554583447052213, 0.03645440997201878, -0.0015287914104006048, 0.000853757330093623, 0.030426677826509596, -0.005235692573939746, -0.011170849391335037, -0.012240617741213912, 0.036516126857428034, -0.022712001957770813, -0.024049213559272642, 0.031578735046493285, -0.05052597532933119, 0.005991730939461309, 0.04001344807470576, -0.02857515636307036, 0.00572943184816548, -0.015233910897950355, 0.008064407059143967, 0.0162728208051246, 0.011880599161477065, -0.000945690569489212, -0.021127922814631942, 0.06085335565301919, -0.04455996006923127, 0.020737046723513057, 0.00869700979120183, -0.042667296499046097, -0.022526851301543034, 0.033553694006041405, 0.019183824160433637, 0.0039936300105299005, 0.028101988607878887, -0.012487487145496131, -0.03314224313625919, 0.012189186382491135, 0.016725415644297924, -0.011572011940462996, 0.013948132517816481, 0.05636855681861259, -0.002929004889655563, 0.026229894228421504, 0.03347140234196882, 0.006367178274889175, -0.0038933391404172633, -0.003839336400022866, -0.012240617741213912, 0.036948148780583216, -0.010023934003371997, -0.07076928138163463, 0.03256621266362217, -0.029295191659898873, 0.008594148005078867, 0.0017165151945298615, -0.01744545094112644, 0.015367632058100537, 0.005222834734259052, 0.00925761011116395, -0.05340612396722596, -0.002219254886682887, 0.02193024977553304, 0.05180147004542376, 0.041864969538145, -0.026908785555858905, -0.18827921467752046, 0.007015211159621944, -0.030241525307636637, 0.031167286039356253, -0.009309040538564137, 0.001902953171407984, -0.02956263398019924, 0.009324470691239043, 0.05213062925113338, -0.057232600664922945, 0.035734374675190264, 0.039828293693187626, -0.0026898498632188534, 0.011644016215203919, 0.015285342256673131, 0.02688821263984076, 0.042008974362336485, 0.010862262170320967, 0.008799872508647383, -0.026476763632703723, 0.0029855792445522287, 0.007663243578693417, -0.012631493832332797, 0.014904751692240729, -0.0664079200433369, 0.019852429961184553, 0.011294284093476147, -0.005261408253301134, -0.020603325563362872, 0.04299645570475572, 0.03450002579113399, -0.03493204771428917, 0.0310644233219107, -0.0024301226192559398, -0.02991236610192701, -0.022465132553488594, 0.05171917838135117, 0.01465788228795851, -0.017414592498421807, 0.025118980977828928, 0.0024314083100917504, -0.0496207893762749, -0.03009751862079997, 0.004857673391178964, -0.014606450929235733, -0.009252466416498118, -0.021169066784023055, 0.0030858698818342187, 0.03507605626377101, -0.0038650520793842543, 0.02345261203326265, 0.004155638231713093, -0.013495537678643156, -0.046576064860815676, -0.1058247628667423, 0.041330084897544264, 0.06533815076213544, -0.010862262170320967, 0.01121199429204874, 0.00503253945204285, 0.017507167826535698, 0.015892230240692196, -0.033656552998196594, -0.04460110590126756, 0.005858009779311126, 0.05900183418957996, 0.061388240293619924, 0.05134887706889561, -0.005328268833376225, 0.035014335653071396, 0.00891302075277942, 0.002468695905467375, 0.026229894228421504, 0.010605106308029674, 0.01785689994826347, -0.05731489232899553, 0.003214447812979865, -0.036022388048863596, 0.009684488339653298, 0.001101269870832057, 0.0019068104767460627, 0.010296519087015605, 0.041474093447026114, -0.04451881796248534, 0.06809486562921169, -0.06928806868123166, 0.026209321312403357, 0.007092357732044813, -0.05106085996993192, -0.004147923621036936, -0.05003223652076675, 0.02705279224269557, 0.02863687324847962, -0.02876030701929814, -0.02462524216926449, 0.03556979507233545, 0.013721835098229818, 0.05599825178086667, 0.01251834558820076, 0.021971393744924152, 0.0006191026290358831, -0.04674064446367049, 0.005071112971084933, -0.0005940299697153856, 0.05089628036707711, -0.023370322231835244, -0.03986943952522392, -0.00365675596131347, -0.028595727416443326, 0.015223625371263871, 0.03882024502268578, -0.032360490954021416, 0.0009906927755409939, -0.058960688357543665, -0.03151701816108403, 0.04311988947557424, -0.0031604450725854676, -0.03268965015973105, -0.03124957584078366, -0.01208632366504558, -0.033286251685741036, -0.018679799825182714, -0.017003143491284775, 0.012230331283204839, -0.05447588952313706, 0.02795798192104222, -0.05159574461053265, -0.002882716759937323, 0.00538998618444678, -0.054640469125991874, 0.006922634900185464, 0.02528356058068374, -0.007112930182401665, -0.022567995270934147, -0.04093920880642538, 0.0059968737028045505, -0.036166396598345446, -0.051390019175641545, -0.00734437036533157, 0.016200816530383674, 0.004237928033140499, 0.002802998573012185, -0.03332739379248697, 0.03935512593799615, 0.01751745521586736, 0.012405197344068725, 0.013680690197516115, 0.03552864924029916, 0.018525505749014383, 0.013156092014924455, -0.003759618213097728, 0.004978536711648453, 0.028410574897570366, -0.015511639676259794, 0.010517673743259027, 0.027217371845550384, 0.011325142536180777, -0.04953849771220231, -0.0012729213553604461, -0.008995310554206826, -0.00717464753347222, -0.004078491193628928, -0.007010067930617407, 0.05488734039291927, -0.0035693229308815266, 0.028904315568779985, -0.05056712116136748, -0.04163867304988093, 0.015953947126101455, -0.017383734055717175, -0.007622098677979714, -0.04124779323347168, 0.004857673391178964, -0.03540521546948064, -0.06755998098861095, 0.00402191707156291, 0.001868237074119304, -0.00012552418257994917, 0.05603939761290296, 0.013927559601798334, 0.010502243590584121, 0.02429608296355486, 0.010954838429757446, 0.027032221189322605, -0.016581407094816078, 0.020109584892153254, 0.054270164088245955, -0.018587222634423646, -0.015182480470550168, 0.017723178788113286, 0.016313964774515712, -0.029048322255616654, -0.007328941143979255, -0.0073649428156884215, -0.015017899936372765, -0.018957527672169565, 0.0029855792445522287, 0.029398054377344426, -0.020263878968321585, -0.013660117281497968, 0.04258500483497351, 0.014174429006080553, -0.09002511354209955, -0.0005059540938655373, -0.01531620069937776, -0.006387750725246027, -0.0924938113102121, -0.04484797716819496, -0.05760290570266886, 0.020603325563362872, 0.0469052240665253, 0.023864061040399683, 0.05760290570266886, -0.014678454272654066, 0.022526851301543034, 0.011078273131898558, 0.00011973818091708464, 0.028101988607878887, 0.028431147813588513, 0.027196800792177418, 0.04653491902877938, 0.0046622353456195215, -0.01434929506694444, 0.007015211159621944, 0.029994655903354418, -0.013814411357666298, 0.01018851360622681, 0.014431584868371846, 0.011901172077495211, -0.04324332324639276, 0.014153857021384997, -0.01596423451543312, -0.04521828220594088, -0.002205111123335735, -0.015984805568806087, 0.027381953311050377, -0.013135520030228899, -0.03596067116345434, 0.04883903346874677, 0.024851538657528562, -0.023411466201226357, -0.001105770021588041, -0.06003045763874513, 0.04455996006923127, 0.021971393744924152, -0.0037107587017078674, 0.014513874669799254, 0.06369235473358731, 0.0038187639496660144, -0.017373448529030694, 0.0033944568700176405, -0.020366741685767138, -0.006470040526673433, -0.028657446164497766, -0.03176388942801143, -0.05110200580196821, 0.009370758355295987, 0.0016316537786001865, -0.015491066760241647, -0.014925324608258876, -0.02068561536479028, -0.017599745017294766, -0.014184715464089627, 0.08171383428470559, 0.019451266480734003, 0.04069233753949798, 0.03530235275203509, 0.03867623647320393, -0.019728994327720854, 0.014822461890813323, -0.017322017170307916, 0.04128893906550797, 0.02297944427807118, 0.03898482462554059, 0.011170849391335037, -0.06352777885602286, 0.009031312691577288, -0.001856665041689744, 0.026394473831276317, -0.05143116500767784, 0.016118526728956268, 0.0016303679713490524, -0.009267895637850434, 0.02886316973674369, -0.04021916978430651, 0.004947678268943823, -0.008090122738505354, -0.08319505443568927, -0.0013834983342361855, 0.009915928522583203, -0.01462702384525388, 0.001955670104551247, -0.026744205953004092, -0.01217889992448206, 0.010533102964611341, -0.010111367499465236, 0.005328268833376225, -0.023061734079498585, 0.022753147789807106, 0.03015923550620923, 0.04324332324639276, -0.03863509064116764, 0.0597012984330355, -0.019615846083588816, 0.0012382052580717662, -0.013207523373647232, -0.006814629419396669, 0.061799687438111775, -0.009175320309736544, -0.028842596820725545, -0.018258063428714017, -0.03178446048138439, 0.004482226055751098, -0.0581377903432696, -0.04653491902877938, 0.008630149211126738, -0.021765668310033046, -0.0655850257543532, 0.017867187337595132, 0.025345277466093, -0.03382113260105141, 0.07702331374069823, -0.024193220246109308, -0.04104207152387093, 0.03507605626377101, -0.012662353206360017, 0.014832748348822396, -0.050237961955657856, 0.031229002924765513, -0.026805922838413352, 0.005173975222869191, 0.0013552111567878525, 0.004322789681900822, 0.0005233120843022153, -0.025262987664665594, 0.08027376369104856, 0.003289023003731114, -0.019965578205316588, -0.008861589394056643, 0.031043852268537734, 0.02950091709478998, -0.015223625371263871, 0.00734437036533157, -0.018330067703454942, -0.02056217973132658, 0.01531620069937776, -0.00034651748718461347, 0.017682034818722173, 0.050855134535040813, 0.008655864890488127, 0.009921072217249034, 0.01971870880103437, 0.03929340905258689, -0.042502716896191284, -0.014328723082248883, 0.009555910874168946, 0.059742440539781436, 0.030015228819372564, 0.03579609156059953, -0.004592802918211514, -0.019091248832319746, 0.016077382759565155, -0.029542061064181092, -0.046576064860815676, -0.028410574897570366, 0.03225762823657587, 0.01537791851610961, 0.05192490381624228, -0.015151621096522948, 0.02643561966331261, 0.05715031272614072, -0.013567541022061489, 0.02043874596050806, 0.03293651770136809, -0.011407432337608183, -0.01941012251134289, -0.02085019496764509, -0.04974422314709342, 0.026641343235558536, 0.02162166162319638, 0.004849958780502806, 0.07048127173325165, -0.023308603483780804, 0.014956183050963506, 0.013495537678643156, -0.0209324847690725, 0.03709215733006506, -0.004191639903422259, -0.029274618743880727, 0.028307714042769994, -0.0439839333218846, 0.02230055295063378, -0.045917742724106064, 0.01077997236889356, 0.014462443311076476, -0.018000908497745317, 0.003103870717688802, 0.020881053410349723, 0.0020482461311570796, -0.0046853791776479935, 0.013022370854774272, 0.014678454272654066, 0.05007338235280304, 0.0004027703029570028, -0.011798309360049658, -0.02320574262898043, -0.034088574921351776, 0.030920416635074034, 0.047193237440198633, -0.010893120613025596, 0.01822720498600939, -0.012682925191055574, 0.04859216592710972, -0.02795798192104222, -0.003474175289773426, 0.019646704526293444, 0.02018158916689418, 0.016180245477010708, 0.030200379475600343, 0.0565331364214674, 0.04447767213044904, -0.047193237440198633, -0.029542061064181092, 0.004374220574962303, 0.031331867504856246, 0.008522143730337944, 0.010481671605888565, -0.03785333845892987, 0.08459398292260036, -0.044230800863521644, 0.030179808422227377, -0.015347060073404981, -0.014606450929235733, 0.020479889929899173, -0.039005395678913556, -0.004543943406821653, -0.021251358448095642, -0.058302369946124415, 0.011325142536180777, 0.013526396121347786, 0.01264178029034187, -0.008300990005417112, -0.008244415883351095, -0.013865841785066484, 0.03143472649701144, -0.07998574659208488, -0.013536682579356859, -0.0025509857068947814, 0.026209321312403357, 0.06007159974549106, -0.023308603483780804, -0.01686942233113459, 0.023596618720099317, -0.04764583041672678, 0.012600635389628167, 0.003325024908270928, 0.025818445221284472, 0.06044190478323698, 0.016838563888429962, 0.02900717642358036, 0.027217371845550384, 0.014801888974795176, -0.011901172077495211, -0.021765668310033046, -0.03612525076630915, -0.03929340905258689, 0.03984886847185095, 0.00708207127403574, -0.04001344807470576, 0.03227819928994883, -0.0032350202633367165, -0.017496882299849213, -0.0077455333801208235, 0.07171561689201757, -0.010605106308029674, -0.06184083327014807, -0.02155994473778712, 0.0025484143252231606, -0.0021241072455747863, 0.023781771238972276, 0.024337226932945974, 0.05612168927697555, -0.03591952533141805, 0.004096492262314159, -0.05665657019228592, -0.007231221655538238, 0.011582298398472069, -0.014092139204653147, 0.016715128254966263, -0.007637527899332029, -0.034973193546325464, 0.055422225033520005, 0.031722743595975135, 0.010023934003371997, 0.047357817043053446, 0.005227977963263589, 0.0006596046843316811, -0.00857357508906072, -0.02314402388092599, 0.004309931842220127, 0.006254029565095844, 0.012322907542641318, -0.03246334994617661, 0.04953849771220231, 0.015830513355282936, 0.013156092014924455, -0.02863687324847962, 0.01441101288367629, -0.04229699146130018, -2.4911971612883783e-05, -0.021724524340641933, -0.013721835098229818, -0.02050046284591732, -0.030118089674172937, -0.014915038150249802, -0.003949913728144577, 0.03495261876766213, -0.013300099633083711, -0.06365121262684137, -0.058837254586725146, 0.012477200687487058, 0.07817537468597228, 0.005868295771658904, -0.002496982966500384, 0.063980371832551, -0.0023298317491433026, -0.009273039332516265, -0.030920416635074034, 0.03873795335861319, -0.005672857726099462, -0.01897810058818771, 0.012497773603505204, -0.03493204771428917, 0.054393601584354835, 0.009093030508309138, 0.02285601050725266, -0.01836092614615957, -0.0030421533666182467, 0.007874111776927765, -0.05258322222766153, -0.01338238943451112, 0.03631040142253693, 0.03351254817400511, -0.0004863459698432053, 0.012631493832332797, 0.025797872305266326, 0.004348504895600915, 0.05575138423922963, -0.03129072167281995, -0.036927577727210247, -0.0010247660274117687, 0.031023279352519587, 0.019914146846593813, 0.05398215071457262, -0.0019106677820841414, 0.0013732121090577595, 0.01791861869631791, 0.007786678280834527, -0.014729885631376843, -0.059207555899180704, 0.015192765997236651, -0.0327925128771766, 0.039807722639814656, -0.009252466416498118, -0.021354219302896014, -0.02729966350962297, -0.031702168817311804, -0.023740625406935983, -0.007226078892194996, 0.01428757818153518, -0.005230549344935209, 0.016447685934665897, -0.012837219267223903, 0.015521926134268867, 0.029295191659898873, -0.0020649612761758523, 0.025921307938730025, 0.009581626553530335, -0.0035847521522338415, 0.015038472852390912, 0.009103316034995621, 0.018371211672846055, -0.0074832347544862895, -0.07945086195148414, -0.018196346543304757, -0.019307259793897337, -0.019502697839456778, -0.12088380956647396, 0.00286471592408274, -0.056985733123285906, -0.015007614409686282, 0.007478091525481753, -0.01462702384525388, 0.05270665972377041, -0.01397899096052111, -0.01438015350964907, -0.023678908521526723, -0.006269459252109454, -0.048139569225291216, 0.014020135861234814, -0.0004387721201853241, -0.020274164495008067, 0.010759399452875414, -0.03297766353340438, -0.020706186418163245, -0.024028640643254495, 0.025571575817002253, -0.05937213922732588, 0.01642711488129293, -0.00993650143860135, -0.01295036751135594, 0.053323832303153365, -0.05640970265064888, 0.052295208853988195, -0.03472632227939806, -0.01876208962661012, 0.03877909919064949, -0.012137755023768357, 0.03143472649701144, 0.013372102976502046, -0.009499335820780339, 0.015429349874832387, -0.007442089853772586, -0.042008974362336485, -0.0072363648845427744, 0.015953947126101455, -0.06624334416577245, -0.007874111776927765, 0.020335883243062507, -0.001873380186708517, 0.011654301741890402, 0.045670875182469026, 0.005071112971084933, -0.1301825664409968, -0.008347278600796648, -0.020212447609598807, 0.04530057014472311, 0.02096334321177713, 0.02991236610192701, 0.01679741805639367, -0.006778627747687503, 0.0001705264613913085, 0.0268264957544315, 0.05007338235280304, 0.005328268833376225, 0.030447250742527743, -0.0027978553440076485, -0.011037128231184854, -0.009334756217925526, 0.08549916887565664, -0.002900717828622554, -0.013228095358342788, -0.01994500528929844, 0.019389549595324743, 0.015100189737800172, 0.026600199266167423, -0.0012227759203041273, -0.036639560628246554, 0.012034892306322804, 0.013166378472933529, -0.005935156351733996, 0.017877472864281617, -0.009828495957812555, -0.01782604150555884, 0.038614519587794674, 0.004387078414642998, -0.03201075696964847, 5.689572667391418e-05, -0.021847959974105633, 0.0006396751376003966, 0.01698257057526663, -0.040424895219197614, -0.039375700716659474, 0.002957291950688572, 0.02357604580408117, 0.04764583041672678, -0.029171757889080354, 0.0036927576330226366, 0.06003045763874513, 0.003139872622228616, 0.025201270779256334, -0.049826514811166005, -0.04908590473567417, 0.0047419532997140116, -0.13042943398263385, 0.05937213922732588, -0.041474093447026114, 0.023987494811218202, 0.018936954756151418, 0.00441022224667147, -0.03877909919064949, -0.027628822715332596, 0.03882024502268578, -0.02149822785237786, 0.006948350579546852, 0.02760824979931445, -0.03725673693291988, -0.0405071868832702, -0.015326487157386834, -0.016200816530383674, -0.009478763836084782, -0.020233020525616954, -0.04460110590126756, -0.03161988087852958, 0.020829622051626945, -0.0004898818524723315, -0.004168496071393787, -0.014801888974795176, 0.0018039481085464807, 0.004963107490296138, 0.05052597532933119, 0.0045825169258637355, -0.02808141569186074, 0.03447945473776102, 0.0296243508656085, 0.010327378461042825, -0.016355110606552006, 0.006891775991819539, -0.007431803395763513, -0.048098427118545284, -0.027217371845550384, -0.0373801707037384, -0.015110476195809245, 0.05147231083971413, -0.017198581536844216, -0.022444561500115628, 0.020582752647344726, 0.02481039468813745, 0.07718788961826269, -0.015552784576973497, -0.0163962564385883]\n"
          ]
        }
      ],
      "source": [
        "# Turn the first text chunk into a vector with the embedding\n",
        "\n",
        "query_result = embeddings.embed_query(texts[0].page_content)\n",
        "print(query_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "QaOY5bIZM3Xz"
      },
      "outputs": [],
      "source": [
        "# Import and initialize Pinecone client\n",
        "\n",
        "import os\n",
        "import pinecone\n",
        "from langchain.vectorstores import Pinecone\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=os.getenv('PINECONE_API_KEY'),  \n",
        "    environment=os.getenv('PINECONE_ENV')  \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "lZhSUt3FNBzN"
      },
      "outputs": [
        {
          "ename": "ForbiddenException",
          "evalue": "(403)\nReason: Forbidden\nHTTP response headers: HTTPHeaderDict({'content-length': '0', 'date': 'Sat, 29 Jul 2023 20:15:37 GMT', 'server': 'envoy', 'connection': 'close'})\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mForbiddenException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[1;32m/home/ayoub/Desktop/Repos/Smart OLAP/langchain-13-min.ipynb Cell 16\u001b[0m in \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayoub/Desktop/Repos/Smart%20OLAP/langchain-13-min.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m index \u001b[39m=\u001b[39m pinecone\u001b[39m.\u001b[39mIndex(\u001b[39m'\u001b[39m\u001b[39mlangchain-quickstart\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayoub/Desktop/Repos/Smart%20OLAP/langchain-13-min.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m index_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlangchain-quickstart\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ayoub/Desktop/Repos/Smart%20OLAP/langchain-13-min.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m search \u001b[39m=\u001b[39m Pinecone\u001b[39m.\u001b[39;49mfrom_documents(texts, embeddings, index_name\u001b[39m=\u001b[39;49mindex_name)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/vectorstores/base.py:164\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m texts \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    163\u001b[0m metadatas \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m--> 164\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_texts(texts, embedding, metadatas\u001b[39m=\u001b[39;49mmetadatas, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/vectorstores/pinecone.py:246\u001b[0m, in \u001b[0;36mPinecone.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, batch_size, text_key, index_name, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m     to_upsert \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(ids_batch, embeds, metadata)\n\u001b[1;32m    245\u001b[0m     \u001b[39m# upsert to Pinecone\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m     index\u001b[39m.\u001b[39;49mupsert(vectors\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(to_upsert), namespace\u001b[39m=\u001b[39;49mnamespace)\n\u001b[1;32m    247\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(index, embedding\u001b[39m.\u001b[39membed_query, text_key, namespace)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pinecone/core/utils/error_handling.py:17\u001b[0m, in \u001b[0;36mvalidate_and_convert_errors.<locals>.inner_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m Config\u001b[39m.\u001b[39mvalidate()  \u001b[39m# raises exceptions in case of invalid config\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     18\u001b[0m \u001b[39mexcept\u001b[39;00m MaxRetryError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     19\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, ProtocolError):\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pinecone/index.py:147\u001b[0m, in \u001b[0;36mIndex.upsert\u001b[0;34m(self, vectors, namespace, batch_size, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39masync_req is not supported when batch_size is provided.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    143\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mTo upsert in parallel, please follow: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    144\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mhttps://docs.pinecone.io/docs/insert-data#sending-upserts-in-parallel\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    146\u001b[0m \u001b[39mif\u001b[39;00m batch_size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_upsert_batch(vectors, namespace, _check_type, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    149\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(batch_size, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m batch_size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    150\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mbatch_size must be a positive integer\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pinecone/index.py:231\u001b[0m, in \u001b[0;36mIndex._upsert_batch\u001b[0;34m(self, vectors, namespace, _check_type, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[39mreturn\u001b[39;00m _dict_to_vector(item)\n\u001b[1;32m    229\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid vector value passed: cannot interpret type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(item)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 231\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vector_api\u001b[39m.\u001b[39;49mupsert(\n\u001b[1;32m    232\u001b[0m     UpsertRequest(\n\u001b[1;32m    233\u001b[0m         vectors\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(_vector_transform, vectors)),\n\u001b[1;32m    234\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49margs_dict,\n\u001b[1;32m    235\u001b[0m         _check_type\u001b[39m=\u001b[39;49m_check_type,\n\u001b[1;32m    236\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m kwargs\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m k \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m _OPENAPI_ENDPOINT_PARAMS}\n\u001b[1;32m    237\u001b[0m     ),\n\u001b[1;32m    238\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m kwargs\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m k \u001b[39min\u001b[39;49;00m _OPENAPI_ENDPOINT_PARAMS}\n\u001b[1;32m    239\u001b[0m )\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pinecone/core/client/api_client.py:776\u001b[0m, in \u001b[0;36mEndpoint.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    766\u001b[0m     \u001b[39m\"\"\" This method is invoked when endpoints are called\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[39m    Example:\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    774\u001b[0m \n\u001b[1;32m    775\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 776\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallable(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pinecone/core/client/api/vector_operations_api.py:956\u001b[0m, in \u001b[0;36mVectorOperationsApi.__init__.<locals>.__upsert\u001b[0;34m(self, upsert_request, **kwargs)\u001b[0m\n\u001b[1;32m    953\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39m_host_index\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39m_host_index\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    954\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mupsert_request\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \\\n\u001b[1;32m    955\u001b[0m     upsert_request\n\u001b[0;32m--> 956\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_with_http_info(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pinecone/core/client/api_client.py:838\u001b[0m, in \u001b[0;36mEndpoint.call_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    834\u001b[0m     header_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_client\u001b[39m.\u001b[39mselect_header_content_type(\n\u001b[1;32m    835\u001b[0m         content_type_headers_list)\n\u001b[1;32m    836\u001b[0m     params[\u001b[39m'\u001b[39m\u001b[39mheader\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m header_list\n\u001b[0;32m--> 838\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi_client\u001b[39m.\u001b[39;49mcall_api(\n\u001b[1;32m    839\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mendpoint_path\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mhttp_method\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    840\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mpath\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    841\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    842\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mheader\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    843\u001b[0m     body\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mbody\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    844\u001b[0m     post_params\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mform\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    845\u001b[0m     files\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mfile\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    846\u001b[0m     response_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mresponse_type\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    847\u001b[0m     auth_settings\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mauth\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    848\u001b[0m     async_req\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39masync_req\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    849\u001b[0m     _check_type\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_check_return_type\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    850\u001b[0m     _return_http_data_only\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_return_http_data_only\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    851\u001b[0m     _preload_content\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_preload_content\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    852\u001b[0m     _request_timeout\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_request_timeout\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    853\u001b[0m     _host\u001b[39m=\u001b[39;49m_host,\n\u001b[1;32m    854\u001b[0m     collection_formats\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mcollection_format\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pinecone/core/client/api_client.py:413\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39m\"\"\"Makes the HTTP request (synchronous) and returns deserialized data.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39mTo make an async_req request, set the async_req parameter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39m    then the method will return the response directly.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m async_req:\n\u001b[0;32m--> 413\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__call_api(resource_path, method,\n\u001b[1;32m    414\u001b[0m                            path_params, query_params, header_params,\n\u001b[1;32m    415\u001b[0m                            body, post_params, files,\n\u001b[1;32m    416\u001b[0m                            response_type, auth_settings,\n\u001b[1;32m    417\u001b[0m                            _return_http_data_only, collection_formats,\n\u001b[1;32m    418\u001b[0m                            _preload_content, _request_timeout, _host,\n\u001b[1;32m    419\u001b[0m                            _check_type)\n\u001b[1;32m    421\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mapply_async(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__call_api, (resource_path,\n\u001b[1;32m    422\u001b[0m                                                method, path_params,\n\u001b[1;32m    423\u001b[0m                                                query_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                                _request_timeout,\n\u001b[1;32m    432\u001b[0m                                                _host, _check_type))\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pinecone/core/client/api_client.py:207\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mexcept\u001b[39;00m ApiException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    206\u001b[0m     e\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mbody\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 207\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    209\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_response \u001b[39m=\u001b[39m response_data\n\u001b[1;32m    211\u001b[0m return_data \u001b[39m=\u001b[39m response_data\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pinecone/core/client/api_client.py:200\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    196\u001b[0m     url \u001b[39m=\u001b[39m _host \u001b[39m+\u001b[39m resource_path\n\u001b[1;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[39m# perform request and return response\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m     response_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    201\u001b[0m         method, url, query_params\u001b[39m=\u001b[39;49mquery_params, headers\u001b[39m=\u001b[39;49mheader_params,\n\u001b[1;32m    202\u001b[0m         post_params\u001b[39m=\u001b[39;49mpost_params, body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    203\u001b[0m         _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    204\u001b[0m         _request_timeout\u001b[39m=\u001b[39;49m_request_timeout)\n\u001b[1;32m    205\u001b[0m \u001b[39mexcept\u001b[39;00m ApiException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    206\u001b[0m     e\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mbody\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pinecone/core/client/api_client.py:459\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrest_client\u001b[39m.\u001b[39mOPTIONS(url,\n\u001b[1;32m    452\u001b[0m                                     query_params\u001b[39m=\u001b[39mquery_params,\n\u001b[1;32m    453\u001b[0m                                     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m                                     _request_timeout\u001b[39m=\u001b[39m_request_timeout,\n\u001b[1;32m    457\u001b[0m                                     body\u001b[39m=\u001b[39mbody)\n\u001b[1;32m    458\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPOST\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 459\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrest_client\u001b[39m.\u001b[39;49mPOST(url,\n\u001b[1;32m    460\u001b[0m                                  query_params\u001b[39m=\u001b[39;49mquery_params,\n\u001b[1;32m    461\u001b[0m                                  headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    462\u001b[0m                                  post_params\u001b[39m=\u001b[39;49mpost_params,\n\u001b[1;32m    463\u001b[0m                                  _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    464\u001b[0m                                  _request_timeout\u001b[39m=\u001b[39;49m_request_timeout,\n\u001b[1;32m    465\u001b[0m                                  body\u001b[39m=\u001b[39;49mbody)\n\u001b[1;32m    466\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPUT\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    467\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrest_client\u001b[39m.\u001b[39mPUT(url,\n\u001b[1;32m    468\u001b[0m                                 query_params\u001b[39m=\u001b[39mquery_params,\n\u001b[1;32m    469\u001b[0m                                 headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    472\u001b[0m                                 _request_timeout\u001b[39m=\u001b[39m_request_timeout,\n\u001b[1;32m    473\u001b[0m                                 body\u001b[39m=\u001b[39mbody)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pinecone/core/client/rest.py:271\u001b[0m, in \u001b[0;36mRESTClientObject.POST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mPOST\u001b[39m(\u001b[39mself\u001b[39m, url, headers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, query_params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, post_params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    270\u001b[0m          body\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, _preload_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, _request_timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 271\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m, url,\n\u001b[1;32m    272\u001b[0m                         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    273\u001b[0m                         query_params\u001b[39m=\u001b[39;49mquery_params,\n\u001b[1;32m    274\u001b[0m                         post_params\u001b[39m=\u001b[39;49mpost_params,\n\u001b[1;32m    275\u001b[0m                         _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    276\u001b[0m                         _request_timeout\u001b[39m=\u001b[39;49m_request_timeout,\n\u001b[1;32m    277\u001b[0m                         body\u001b[39m=\u001b[39;49mbody)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pinecone/core/client/rest.py:222\u001b[0m, in \u001b[0;36mRESTClientObject.request\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[39mraise\u001b[39;00m UnauthorizedException(http_resp\u001b[39m=\u001b[39mr)\n\u001b[1;32m    221\u001b[0m \u001b[39mif\u001b[39;00m r\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m \u001b[39m403\u001b[39m:\n\u001b[0;32m--> 222\u001b[0m     \u001b[39mraise\u001b[39;00m ForbiddenException(http_resp\u001b[39m=\u001b[39mr)\n\u001b[1;32m    224\u001b[0m \u001b[39mif\u001b[39;00m r\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m \u001b[39m404\u001b[39m:\n\u001b[1;32m    225\u001b[0m     \u001b[39mraise\u001b[39;00m NotFoundException(http_resp\u001b[39m=\u001b[39mr)\n",
            "\u001b[0;31mForbiddenException\u001b[0m: (403)\nReason: Forbidden\nHTTP response headers: HTTPHeaderDict({'content-length': '0', 'date': 'Sat, 29 Jul 2023 20:15:37 GMT', 'server': 'envoy', 'connection': 'close'})\n"
          ]
        }
      ],
      "source": [
        "# Upload vectors to Pinecone\n",
        "index = pinecone.Index('langchain-quickstart')\n",
        "index_name = \"langchain-quickstart\"\n",
        "search = Pinecone.from_documents(texts, embeddings, index_name=index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "cCXVuXwPNKcc"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'search' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/ayoub/Desktop/Repos/Smart OLAP/langchain-13-min.ipynb Cell 17\u001b[0m in \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayoub/Desktop/Repos/Smart%20OLAP/langchain-13-min.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Do a simple vector similarity search\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayoub/Desktop/Repos/Smart%20OLAP/langchain-13-min.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWhat is magical about an autoencoder?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ayoub/Desktop/Repos/Smart%20OLAP/langchain-13-min.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m result \u001b[39m=\u001b[39m search\u001b[39m.\u001b[39msimilarity_search(query)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayoub/Desktop/Repos/Smart%20OLAP/langchain-13-min.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'search' is not defined"
          ]
        }
      ],
      "source": [
        "# Do a simple vector similarity search\n",
        "\n",
        "query = \"What is magical about an autoencoder?\"\n",
        "result = search.similarity_search(query)\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ogz8luZNRnJ"
      },
      "outputs": [],
      "source": [
        "# Import Python REPL tool and instantiate Python agent\n",
        "\n",
        "from langchain.agents.agent_toolkits import create_python_agent\n",
        "from langchain.tools.python.tool import PythonREPLTool\n",
        "from langchain.python import PythonREPL\n",
        "from langchain.llms.openai import OpenAI\n",
        "\n",
        "agent_executor = create_python_agent(\n",
        "    llm=OpenAI(temperature=0, max_tokens=1000),\n",
        "    tool=PythonREPLTool(),\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVHMDj0sNi09"
      },
      "outputs": [],
      "source": [
        "# Execute the Python agent\n",
        "\n",
        "agent_executor.run(\"Find the roots (zeros) if the quadratic function 3 * x**2 + 2*x -1\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyONM96f7/m0jUCD9c87+MQy",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
